from PyPDF2 import PdfReader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI
import streamlit as st
import os

os.environ["OPENAI_API_KEY"] = 

#Define Streamlit app
def app():

    st.title("Welcome to the OceanML Demo App")

    # Add a file uploader to the app
    uploaded_file = st.file_uploader("Upload a research paper (PDF)", type="pdf")

    # location of the pdf file/files. 
    reader = PdfReader(uploaded_file)

    # We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits. 

    text_splitter = CharacterTextSplitter(        
        separator = "\n",
        chunk_size = 1000,
        chunk_overlap  = 200,
        length_function = len,
    )
    texts = text_splitter.split_text(raw_text)

    # Download embeddings from OpenAI
    embeddings = OpenAIEmbeddings()
    docsearch = FAISS.from_texts(texts, embeddings)

    chain = load_qa_chain(OpenAI(), chain_type="stuff")

    query = st.text_input("Enter a question")
    docs = docsearch.similarity_search(query)
    ans = chain.run(input_documents=docs, question=query)

    # Display the answer to the user
    st.subheader("Answer:")
    st.write(ans)

# Run the app
if __name__ == "__main__":
    app()


